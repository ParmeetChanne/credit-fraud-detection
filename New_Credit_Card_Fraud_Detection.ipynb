{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMMthcq2U0rqkuqrwk73L3G"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Importing required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV  # Functions for splitting data and cross-validation\n",
        "from sklearn.linear_model import LogisticRegression  # Logistic Regression algorithm\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix  # Functions to measure model performance\n",
        "from sklearn.preprocessing import StandardScaler  # Function for scaling features\n",
        "\n",
        "# Loading the dataset to a Pandas DataFrame\n",
        "credit_card_data = pd.read_csv('/content/creditcard.csv')\n",
        "\n",
        "# Data Preprocessing\n",
        "scaler = StandardScaler()  # Initializing a scaler to normalize data\n",
        "credit_card_data['Normalized_Amount'] = scaler.fit_transform(credit_card_data['Amount'].values.reshape(-1, 1))  # Normalizing 'Amount' column\n",
        "credit_card_data.drop(['Time', 'Amount'], axis=1, inplace=True)  # Dropping 'Time' and original 'Amount' columns\n",
        "\n",
        "# Handling Imbalanced Data\n",
        "fraud = credit_card_data[credit_card_data['Class'] == 1]  # Extracting rows where 'Class' is fraud (1)\n",
        "legit = credit_card_data[credit_card_data['Class'] == 0].sample(n=len(fraud))  # Extracting random legit samples matching fraud count\n",
        "balanced_data = pd.concat([fraud, legit])  # Creating a balanced dataset by combining fraud and legit samples\n",
        "\n",
        "X = balanced_data.drop('Class', axis=1)\n",
        "y = balanced_data['Class']\n",
        "\n",
        "# Splitting the data into features and targets for training and testing\n",
        "# 'test_size=0.2' splits 20% of the data for testing, 'random_state=42' ensures reproducibility\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Model Building and Training\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Hyperparameter Tuning using GridSearchCV\n",
        "# Define hyperparameters for tuning (regularization parameter)\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Grid search with 5-fold cross-validation using F1 score\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='f1')\n",
        "\n",
        "# Training the model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Selecting the best model based on cross-validation results\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluating the Model on Test Data\n",
        "# Training the best model on the entire training set\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions on the test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Calculating Evaluation Metrics\n",
        "# Calculating the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Calculating precision (true positives / predicted positives)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "\n",
        "# Calculating recall (true positives / actual positives)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "# Calculating F1 score (harmonic mean of precision and recall)\n",
        "# A higher F1 score implies a good balance between identifying actual fraudulent transactions (recall) while minimizing false positives (precision).\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Generating a confusion matrix for performance visualization\n",
        "# Structure of Confusion matrix:\n",
        "'''\n",
        "Actual/Predicted     Positive Class (1)    Negative Class (0)\n",
        "Positive Class (1)        TP                    FN\n",
        "Negative Class (0)        FP                    TN\n",
        "'''\n",
        "# Our result shows that False positives and False negatives are very low => Model is good! (More accurate)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Displaying Evaluation Metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Cross-Validation to Assess Model Performance\n",
        "\n",
        "# Performing 5-fold cross-validation using F1 score\n",
        "# Meaning: dataset is divided into 5 equal parts, 4 for training and 1 for testing\n",
        "cv_scores = cross_val_score(best_model, X, y, cv=5, scoring='f1')\n",
        "\n",
        "print(\"Cross-Validation Scores:\", cv_scores)\n",
        "\n",
        "# Calculating and displaying the mean cross-validation score\n",
        "print(\"Mean CV Score:\", np.mean(cv_scores))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgJl8z5yjYTy",
        "outputId": "f9c026af-b32a-4edc-d78a-6049c7a4c7e5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9122807017543859\n",
            "Precision: 0.9259259259259259\n",
            "Recall: 0.8928571428571429\n",
            "F1 Score: 0.9090909090909091\n",
            "Confusion Matrix:\n",
            "[[27  2]\n",
            " [ 3 25]]\n",
            "Cross-Validation Scores: [0.98245614 0.92592593 0.94545455 0.92307692 0.98245614]\n",
            "Mean CV Score: 0.9518739350318297\n"
          ]
        }
      ]
    }
  ]
}